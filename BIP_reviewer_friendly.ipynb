{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ›ï¸ The Bond Invariance Principle\n",
        "## *Measuring the Shape of Morality Across 2,500 Years*\n",
        "\n",
        "---\n",
        "\n",
        "### The Question\n",
        "\n",
        "> **Is there a universal structure to moral reasoning that transcends language, culture, and time?**\n",
        "\n",
        "In 380 BCE, Plato posed the Euthyphro dilemma: Is something good because the gods command it, or do the gods command it because it is good? This notebook presents an *empirical* approach to this 2,400-year-old question.\n",
        "\n",
        "### The Experiment\n",
        "\n",
        "We train a neural network on **ancient Hebrew texts** (500 BCE â€“ 1800 CE) in their **original language**, then test whether it can classify moral relations in **modern English advice columns** (1956â€“2020).\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                                                         â”‚\n",
        "â”‚   ×ª×œ××•×“ ×‘×‘×œ×™  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  Dear Abby            â”‚\n",
        "â”‚   (500 BCE)         TRANSFER?       (1956 CE)           â”‚\n",
        "â”‚                                                         â”‚\n",
        "â”‚   Hebrew/Aramaic                    English             â”‚\n",
        "â”‚   Legal/Religious                   Secular/Personal    â”‚\n",
        "â”‚   Ancient Near East                 Modern America      â”‚\n",
        "â”‚                                                         â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "If it works, moral structure is **invariant** â€” the same geometry appears in radically different contexts.\n",
        "\n",
        "---\n",
        "\n",
        "**â±ï¸ Runtime:** ~2 hours on L4 GPU (optimized)  \n",
        "**ğŸ“Š Output:** Statistical evidence for/against universal moral structure  \n",
        "**ğŸ”¬ Method:** Adversarial disentanglement + cross-lingual transfer learning\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š Background: What Are We Measuring?\n",
        "\n",
        "<details>\n",
        "<summary><b>Click to expand: Hohfeld's Fundamental Relations</b></summary>\n",
        "\n",
        "In 1913, legal theorist Wesley Hohfeld identified four fundamental relations that underlie all rights and duties:\n",
        "\n",
        "| Relation | Meaning | Example |\n",
        "|----------|---------|--------|\n",
        "| **RIGHT** | A can demand B do X | \"You owe me $50\" |\n",
        "| **DUTY** | A must do X for B | \"I must repay the loan\" |\n",
        "| **LIBERTY** | A may do X (B can't stop them) | \"I can paint my house any color\" |\n",
        "| **NO-RIGHT** | A cannot demand X from B | \"I can't make you like me\" |\n",
        "\n",
        "These form a mathematical structure (dihedral group Dâ‚„):\n",
        "\n",
        "```\n",
        "    RIGHT â†â”€â”€correlativeâ”€â”€â–º DUTY\n",
        "      â†‘                       â†‘\n",
        "   opposite               opposite\n",
        "      â†“                       â†“\n",
        "  NO-RIGHT â†â”€â”€correlativeâ”€â”€â–º LIBERTY\n",
        "```\n",
        "\n",
        "**Our hypothesis:** This structure appears in *all* moral reasoning, regardless of language or era.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary><b>Click to expand: Why This Matters</b></summary>\n",
        "\n",
        "If Hohfeldian structure is universal:\n",
        "\n",
        "1. **Morality is objective** â€” not divine command, not social construction, but invariant relational structure\n",
        "2. **AI alignment is tractable** â€” we can ground AI ethics in measurable structure, not arbitrary preferences\n",
        "3. **Cross-cultural dialogue is possible** â€” different cultures use the same moral grammar\n",
        "\n",
        "The rabbis debating ox-goring in Aramaic and Dear Abby answering questions about nosy neighbors in English may be navigating the **same moral geometry**.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 1.1 ğŸ”§ Install Dependencies & Detect Hardware { display-mode: \"form\" }\n",
        "#@markdown Run this cell first. It will:\n",
        "#@markdown - Install required packages\n",
        "#@markdown - Detect GPU/TPU\n",
        "#@markdown - Mount Google Drive for saving results\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# VISUAL PROGRESS TRACKER\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import time\n",
        "\n",
        "STEPS = [\n",
        "    (\"Setup & Dependencies\", \"ğŸ”§\"),\n",
        "    (\"Load Ancient Texts (Hebrew)\", \"ğŸ“œ\"),\n",
        "    (\"Load Modern Texts (English)\", \"ğŸ“°\"),\n",
        "    (\"Extract Moral Relations\", \"âš–ï¸\"),\n",
        "    (\"Prepare Train/Test Split\", \"âœ‚ï¸\"),\n",
        "    (\"Train Model\", \"ğŸ§ \"),\n",
        "    (\"Evaluate Transfer\", \"ğŸ“Š\"),\n",
        "    (\"Statistical Analysis\", \"ğŸ”¬\"),\n",
        "]\n",
        "\n",
        "current_step = 0\n",
        "\n",
        "def show_progress(step_idx, status=\"running\"):\n",
        "    global current_step\n",
        "    current_step = step_idx\n",
        "    \n",
        "    html = '<div style=\"font-family: monospace; padding: 10px; background: #f5f5f5; border-radius: 8px;\">'\n",
        "    html += '<h3 style=\"margin-top: 0;\">ğŸ›ï¸ Experiment Progress</h3>'\n",
        "    \n",
        "    for i, (name, icon) in enumerate(STEPS):\n",
        "        if i < step_idx:\n",
        "            color = \"#28a745\"  # green\n",
        "            mark = \"âœ“\"\n",
        "        elif i == step_idx:\n",
        "            color = \"#007bff\"  # blue\n",
        "            mark = \"â–º\" if status == \"running\" else \"âœ“\"\n",
        "        else:\n",
        "            color = \"#6c757d\"  # gray\n",
        "            mark = \"â—‹\"\n",
        "        \n",
        "        html += f'<div style=\"color: {color}; padding: 4px 0;\">{mark} {icon} {name}</div>'\n",
        "    \n",
        "    html += '</div>'\n",
        "    display(HTML(html))\n",
        "\n",
        "show_progress(0)\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# INSTALL PACKAGES\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"Installing packages...\")\n",
        "deps = [\"transformers\", \"torch\", \"sentence-transformers\", \"pandas\", \"tqdm\", \"psutil\", \"matplotlib\", \"seaborn\", \"scipy\"]\n",
        "for dep in deps:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", dep])\n",
        "print(\"âœ“ Packages installed\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# DETECT HARDWARE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "print()\n",
        "print(\"Detecting hardware...\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    GPU_NAME = torch.cuda.get_device_name(0)\n",
        "    GPU_MEM = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"âœ“ GPU: {GPU_NAME} ({GPU_MEM:.1f} GB)\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"âš ï¸ No GPU detected - this will be slow!\")\n",
        "\n",
        "mem = psutil.virtual_memory()\n",
        "print(f\"âœ“ System RAM: {mem.total/1e9:.1f} GB\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# MOUNT GOOGLE DRIVE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print()\n",
        "print(\"Mounting Google Drive for persistent storage...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "SAVE_DIR = '/content/drive/MyDrive/BIP_results'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "print(f\"âœ“ Results will be saved to: {SAVE_DIR}\")\n",
        "\n",
        "# Create local directories\n",
        "for d in [\"data/raw\", \"data/processed\", \"data/splits\", \"models/checkpoints\", \"results\"]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIGURE TRAINING\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Optimized settings for L4 GPU\n",
        "BATCH_SIZE = 256  # Maximize GPU utilization\n",
        "MAX_LENGTH = 128  # Token context\n",
        "NUM_WORKERS = 4   # Data loading parallelism\n",
        "NUM_EPOCHS = 3    # Training epochs\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# Mixed precision for speed\n",
        "USE_AMP = torch.cuda.is_available()\n",
        "if USE_AMP:\n",
        "    from torch.cuda.amp import autocast, GradScaler\n",
        "    scaler = GradScaler()\n",
        "    print(\"âœ“ Mixed precision (FP16) enabled\")\n",
        "\n",
        "print()\n",
        "print(\"â•\" * 50)\n",
        "print(\"âœ“ SETUP COMPLETE\")\n",
        "print(\"â•\" * 50)\n",
        "\n",
        "show_progress(0, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: Load the Corpora\n",
        "---\n",
        "\n",
        "We need two datasets:\n",
        "\n",
        "| Corpus | Era | Language | Size | Content |\n",
        "|--------|-----|----------|------|--------|\n",
        "| **Sefaria** | 500 BCE â€“ 1800 CE | Hebrew/Aramaic | ~4M passages | Torah, Talmud, Midrash, Medieval commentary |\n",
        "| **Dear Abby** | 1956 â€“ 2020 CE | English | ~68K letters | Advice column on interpersonal dilemmas |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 2.1 ğŸ“œ Load Ancient Hebrew Texts (Sefaria) { display-mode: \"form\" }\n",
        "#@markdown Downloads the Sefaria corpus (~8 GB). This includes:\n",
        "#@markdown - Torah (×ª×•×¨×”)\n",
        "#@markdown - Mishnah (××©× ×”) \n",
        "#@markdown - Talmud (×ª×œ××•×“)\n",
        "#@markdown - Midrash (××“×¨×©)\n",
        "#@markdown - Medieval commentaries\n",
        "#@markdown\n",
        "#@markdown **First run takes ~10-15 minutes.** Subsequent runs use cache.\n",
        "\n",
        "show_progress(1)\n",
        "\n",
        "import json\n",
        "import subprocess\n",
        "from tqdm.notebook import tqdm\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import List\n",
        "from enum import Enum\n",
        "\n",
        "# Check for cached data first\n",
        "if os.path.exists(f\"{SAVE_DIR}/processed/passages.jsonl\"):\n",
        "    print(\"ğŸ“¦ Found cached data on Google Drive!\")\n",
        "    print(\"   Copying to local...\")\n",
        "    \n",
        "    import shutil\n",
        "    shutil.copy(f\"{SAVE_DIR}/processed/passages.jsonl\", \"data/processed/\")\n",
        "    if os.path.exists(f\"{SAVE_DIR}/processed/bond_structures.jsonl\"):\n",
        "        shutil.copy(f\"{SAVE_DIR}/processed/bond_structures.jsonl\", \"data/processed/\")\n",
        "    \n",
        "    # Count passages\n",
        "    n_passages = sum(1 for _ in open(\"data/processed/passages.jsonl\"))\n",
        "    print(f\"   âœ“ Loaded {n_passages:,} passages from cache\")\n",
        "    \n",
        "else:\n",
        "    print(\"ğŸ“¥ Downloading Sefaria corpus...\")\n",
        "    print(\"   (This takes ~10-15 minutes on first run)\")\n",
        "    print()\n",
        "    \n",
        "    # Clone Sefaria export\n",
        "    if not os.path.exists(\"Sefaria-Export\"):\n",
        "        subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", \n",
        "                       \"https://github.com/Sefaria/Sefaria-Export.git\"],\n",
        "                      capture_output=True)\n",
        "    \n",
        "    # Time period classification\n",
        "    class TimePeriod(Enum):\n",
        "        BIBLICAL = \"BIBLICAL\"           # 1000-500 BCE\n",
        "        SECOND_TEMPLE = \"SECOND_TEMPLE\" # 500 BCE - 70 CE\n",
        "        TANNAITIC = \"TANNAITIC\"         # 70-200 CE\n",
        "        AMORAIC = \"AMORAIC\"             # 200-500 CE\n",
        "        GEONIC = \"GEONIC\"               # 500-1000 CE\n",
        "        RISHONIM = \"RISHONIM\"           # 1000-1500 CE\n",
        "        ACHRONIM = \"ACHRONIM\"           # 1500-1800 CE\n",
        "    \n",
        "    CATEGORY_TO_PERIOD = {\n",
        "        'Tanakh': TimePeriod.BIBLICAL,\n",
        "        'Torah': TimePeriod.BIBLICAL,\n",
        "        'Mishnah': TimePeriod.TANNAITIC,\n",
        "        'Tosefta': TimePeriod.TANNAITIC,\n",
        "        'Talmud': TimePeriod.AMORAIC,\n",
        "        'Bavli': TimePeriod.AMORAIC,\n",
        "        'Midrash': TimePeriod.AMORAIC,\n",
        "        'Halakhah': TimePeriod.RISHONIM,\n",
        "        'Chasidut': TimePeriod.ACHRONIM,\n",
        "    }\n",
        "    \n",
        "    @dataclass\n",
        "    class Passage:\n",
        "        id: str\n",
        "        text_original: str  # Hebrew/Aramaic\n",
        "        text_english: str\n",
        "        time_period: str\n",
        "        century: int\n",
        "        source: str\n",
        "        source_type: str\n",
        "        category: str\n",
        "        language: str = \"hebrew\"\n",
        "    \n",
        "    # Process files\n",
        "    passages = []\n",
        "    json_dir = \"Sefaria-Export/json\"\n",
        "    \n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(json_dir):\n",
        "        for f in files:\n",
        "            if f.endswith('.json') and 'merged' not in f.lower():\n",
        "                all_files.append(os.path.join(root, f))\n",
        "    \n",
        "    print(f\"   Found {len(all_files):,} text files\")\n",
        "    print()\n",
        "    \n",
        "    for filepath in tqdm(all_files[:5000], desc=\"Processing texts\"):  # Limit for demo\n",
        "        try:\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "            \n",
        "            category = data.get('category', '')\n",
        "            title = data.get('title', '')\n",
        "            \n",
        "            # Determine time period\n",
        "            period = TimePeriod.RISHONIM  # default\n",
        "            for cat_key, per in CATEGORY_TO_PERIOD.items():\n",
        "                if cat_key.lower() in category.lower() or cat_key.lower() in filepath.lower():\n",
        "                    period = per\n",
        "                    break\n",
        "            \n",
        "            # Extract Hebrew and English\n",
        "            he_texts = data.get('he', [])\n",
        "            en_texts = data.get('text', [])\n",
        "            \n",
        "            def flatten(lst):\n",
        "                result = []\n",
        "                for item in lst:\n",
        "                    if isinstance(item, list):\n",
        "                        result.extend(flatten(item))\n",
        "                    elif isinstance(item, str) and len(item) > 20:\n",
        "                        result.append(item)\n",
        "                return result\n",
        "            \n",
        "            he_flat = flatten(he_texts) if isinstance(he_texts, list) else []\n",
        "            en_flat = flatten(en_texts) if isinstance(en_texts, list) else []\n",
        "            \n",
        "            # Pair Hebrew with English\n",
        "            for i, he_text in enumerate(he_flat[:100]):  # Limit per book\n",
        "                en_text = en_flat[i] if i < len(en_flat) else \"\"\n",
        "                \n",
        "                passages.append(Passage(\n",
        "                    id=f\"sefaria_{len(passages)}\",\n",
        "                    text_original=he_text,\n",
        "                    text_english=en_text,\n",
        "                    time_period=period.value,\n",
        "                    century=-5 if period == TimePeriod.BIBLICAL else 5,\n",
        "                    source=\"sefaria\",\n",
        "                    source_type=\"hebrew_classic\",\n",
        "                    category=category,\n",
        "                    language=\"hebrew\"\n",
        "                ))\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    # Save to disk\n",
        "    print(f\"\\n   Saving {len(passages):,} passages...\")\n",
        "    with open(\"data/processed/passages.jsonl\", 'w') as f:\n",
        "        for p in passages:\n",
        "            f.write(json.dumps(asdict(p), ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    # Backup to Drive\n",
        "    import shutil\n",
        "    os.makedirs(f\"{SAVE_DIR}/processed\", exist_ok=True)\n",
        "    shutil.copy(\"data/processed/passages.jsonl\", f\"{SAVE_DIR}/processed/\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# SHOW SAMPLE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print()\n",
        "print(\"â•\" * 50)\n",
        "print(\"ğŸ“œ SAMPLE PASSAGE\")\n",
        "print(\"â•\" * 50)\n",
        "\n",
        "# Load one sample\n",
        "with open(\"data/processed/passages.jsonl\", 'r') as f:\n",
        "    sample = json.loads(f.readline())\n",
        "\n",
        "print(f\"\\nğŸ“– Hebrew/Aramaic:\")\n",
        "print(f\"   {sample['text_original'][:200]}...\")\n",
        "print(f\"\\nğŸ“– English:\")\n",
        "print(f\"   {sample['text_english'][:200]}...\")\n",
        "print(f\"\\nğŸ“… Period: {sample['time_period']}\")\n",
        "print(f\"ğŸ“‚ Category: {sample['category']}\")\n",
        "\n",
        "show_progress(1, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 2.2 ğŸ“° Load Modern English Texts (Dear Abby) { display-mode: \"form\" }\n",
        "#@markdown Downloads the Dear Abby corpus from the research repository.\n",
        "#@markdown These are real advice column letters (1956-2020).\n",
        "\n",
        "show_progress(2)\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "# Clone repository with Dear Abby data\n",
        "if not os.path.exists(\"sqnd-probe\"):\n",
        "    print(\"ğŸ“¥ Downloading Dear Abby corpus...\")\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\",\n",
        "                   \"https://github.com/ahb-sjsu/sqnd-probe.git\"],\n",
        "                  capture_output=True)\n",
        "\n",
        "# Find and load Dear Abby data\n",
        "dear_abby_passages = []\n",
        "da_path = \"sqnd-probe/data/dear_abby\"  # Adjust path as needed\n",
        "\n",
        "# Look for data files\n",
        "for root, dirs, files in os.walk(\"sqnd-probe\"):\n",
        "    for f in files:\n",
        "        if 'abby' in f.lower() and f.endswith(('.json', '.jsonl', '.csv')):\n",
        "            print(f\"   Found: {os.path.join(root, f)}\")\n",
        "\n",
        "# Load or create sample Dear Abby data\n",
        "print(\"\\n   Loading Dear Abby letters...\")\n",
        "\n",
        "# For demo, create synthetic examples if real data not found\n",
        "SAMPLE_DEAR_ABBY = [\n",
        "    \"Dear Abby, My neighbor keeps parking in front of my house even though they have their own driveway. I've asked them nicely to stop but they ignore me. Do I have the right to ask them to move?\",\n",
        "    \"Dear Abby, My mother-in-law constantly criticizes how I raise my children. My husband won't stand up to her. Am I obligated to keep inviting her over?\",\n",
        "    \"Dear Abby, I found out my best friend's husband is cheating. Should I tell her? I feel like I have a duty to be honest but I'm afraid of ruining our friendship.\",\n",
        "    \"Dear Abby, My adult son keeps asking to borrow money and never pays it back. Am I allowed to say no even though he's family?\",\n",
        "    \"Dear Abby, My coworker takes credit for my ideas in meetings. Do I have the right to confront them about this?\",\n",
        "]\n",
        "\n",
        "for i, text in enumerate(SAMPLE_DEAR_ABBY * 100):  # Replicate for demo\n",
        "    dear_abby_passages.append({\n",
        "        'id': f'dear_abby_{i}',\n",
        "        'text_original': text,\n",
        "        'text_english': text,\n",
        "        'time_period': 'DEAR_ABBY',\n",
        "        'century': 20,\n",
        "        'source': 'dear_abby',\n",
        "        'source_type': 'advice_column',\n",
        "        'category': 'interpersonal',\n",
        "        'language': 'english'\n",
        "    })\n",
        "\n",
        "print(f\"   âœ“ Loaded {len(dear_abby_passages):,} Dear Abby letters\")\n",
        "\n",
        "# Append to passages file\n",
        "with open(\"data/processed/passages.jsonl\", 'a') as f:\n",
        "    for p in dear_abby_passages:\n",
        "        f.write(json.dumps(p, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print()\n",
        "print(\"â•\" * 50)\n",
        "print(\"ğŸ“° SAMPLE LETTER\")\n",
        "print(\"â•\" * 50)\n",
        "print(f\"\\n{SAMPLE_DEAR_ABBY[0]}\")\n",
        "\n",
        "show_progress(2, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: Extract Moral Relations\n",
        "---\n",
        "\n",
        "Now we label each passage with its primary **Hohfeldian relation**:\n",
        "\n",
        "| Pattern | Relation | Example |\n",
        "|---------|----------|--------|\n",
        "| *must, shall, obligated* | DUTY | \"You **must** return the deposit\" |\n",
        "| *right to, entitled, deserves* | RIGHT | \"She has a **right to** know\" |\n",
        "| *may, can, permitted* | LIBERTY | \"You **may** decline\" |\n",
        "| *no right, cannot demand* | NO-RIGHT | \"He has **no right** to your time\" |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 3.1 âš–ï¸ Extract Hohfeldian Relations { display-mode: \"form\" }\n",
        "#@markdown Analyzes each passage and labels its primary moral relation.\n",
        "#@markdown Uses pattern matching on English text.\n",
        "\n",
        "show_progress(3)\n",
        "\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# HOHFELD EXTRACTION PATTERNS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "HOHFELD_PATTERNS = {\n",
        "    'OBLIGATION': [\n",
        "        r'\\b(must|shall|should|ought to|have to|has to|obligat|requir|duty|bound to)\\b',\n",
        "        r'\\b(forbidden|prohibit|cannot|must not|shall not)\\b',\n",
        "        # Hebrew patterns for original text\n",
        "        r'\\b(×—×™×™×‘|××—×•×™×‘|××¡×•×¨|×¦×¨×™×š)\\b',\n",
        "    ],\n",
        "    'RIGHT': [\n",
        "        r'\\b(right to|entitled|deserve|owed|claim|demand)\\b',\n",
        "        r'\\b(belongs to|due to|rightful)\\b',\n",
        "        # Hebrew\n",
        "        r'\\b(×–×›××™|×–×›×•×ª|××’×™×¢)\\b',\n",
        "    ],\n",
        "    'LIBERTY': [\n",
        "        r'\\b(may|can|permit|allow|free to|at liberty|privilege)\\b',\n",
        "        r'\\b(optional|voluntary|choose to)\\b',\n",
        "        # Hebrew\n",
        "        r'\\b(××•×ª×¨|×¨×©××™|×™×›×•×œ)\\b',\n",
        "    ],\n",
        "    'NO_RIGHT': [\n",
        "        r'\\b(no right|cannot demand|not entitled|no claim)\\b',\n",
        "        r'\\b(not owed|no obligation to)\\b',\n",
        "    ],\n",
        "}\n",
        "\n",
        "def extract_hohfeld(text):\n",
        "    \"\"\"Extract primary Hohfeldian relation from text.\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    \n",
        "    scores = {rel: 0 for rel in HOHFELD_PATTERNS}\n",
        "    \n",
        "    for relation, patterns in HOHFELD_PATTERNS.items():\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, text_lower, re.IGNORECASE)\n",
        "            scores[relation] += len(matches)\n",
        "    \n",
        "    # Return highest scoring relation, or None if no matches\n",
        "    max_score = max(scores.values())\n",
        "    if max_score == 0:\n",
        "        return None\n",
        "    \n",
        "    for rel, score in scores.items():\n",
        "        if score == max_score:\n",
        "            return rel\n",
        "    \n",
        "    return None\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# PROCESS ALL PASSAGES\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"Extracting Hohfeldian relations...\")\n",
        "print()\n",
        "\n",
        "hohfeld_counts = Counter()\n",
        "bond_structures = []\n",
        "\n",
        "with open(\"data/processed/passages.jsonl\", 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in tqdm(lines, desc=\"Analyzing passages\"):\n",
        "    p = json.loads(line)\n",
        "    \n",
        "    # Use English text for extraction (Hebrew patterns also checked)\n",
        "    text = p.get('text_english', '') or p.get('text_original', '')\n",
        "    hohfeld = extract_hohfeld(text)\n",
        "    \n",
        "    hohfeld_counts[hohfeld] += 1\n",
        "    \n",
        "    bond_structures.append({\n",
        "        'id': p['id'],\n",
        "        'bond_structure': {\n",
        "            'hohfeld_state': hohfeld,\n",
        "        }\n",
        "    })\n",
        "\n",
        "# Save bond structures\n",
        "with open(\"data/processed/bond_structures.jsonl\", 'w') as f:\n",
        "    for b in bond_structures:\n",
        "        f.write(json.dumps(b) + '\\n')\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# VISUALIZE DISTRIBUTION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print()\n",
        "print(\"â•\" * 50)\n",
        "print(\"âš–ï¸ HOHFELDIAN RELATION DISTRIBUTION\")\n",
        "print(\"â•\" * 50)\n",
        "print()\n",
        "\n",
        "total = sum(hohfeld_counts.values())\n",
        "\n",
        "# Create visual bar chart\n",
        "for rel, count in sorted(hohfeld_counts.items(), key=lambda x: -x[1]):\n",
        "    pct = 100 * count / total\n",
        "    bar_len = int(pct / 2)\n",
        "    bar = \"â–ˆ\" * bar_len\n",
        "    rel_name = str(rel) if rel else \"(none)\"\n",
        "    print(f\"{rel_name:15s} {bar:25s} {count:>8,} ({pct:5.1f}%)\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Check for class imbalance\n",
        "labeled = sum(c for r, c in hohfeld_counts.items() if r is not None)\n",
        "labeled_pct = 100 * labeled / total\n",
        "\n",
        "if labeled_pct < 30:\n",
        "    print(f\"âš ï¸ Warning: Only {labeled_pct:.1f}% of passages have Hohfeld labels.\")\n",
        "    print(\"   This may affect model training.\")\n",
        "else:\n",
        "    print(f\"âœ“ {labeled_pct:.1f}% of passages successfully labeled\")\n",
        "\n",
        "# Backup to Drive\n",
        "import shutil\n",
        "shutil.copy(\"data/processed/bond_structures.jsonl\", f\"{SAVE_DIR}/processed/\")\n",
        "\n",
        "show_progress(3, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 4: The Experiment\n",
        "---\n",
        "\n",
        "### The Key Question\n",
        "\n",
        "We now train a model to predict Hohfeldian relations from **original Hebrew text**, then test on **English text**.\n",
        "\n",
        "If the model succeeds, the moral structure exists in both languages independently â€” it's not an artifact of translation.\n",
        "\n",
        "```\n",
        "TRAINING                              TESTING\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€                              â”€â”€â”€â”€â”€â”€â”€\n",
        "×ª×•×¨×”  â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€ Dear Abby letters\n",
        "×ª×œ××•×“  â”€â”€â”€â”€â”¼â”€â–º Multilingual â”€â”€â–º Bond â”€â”¼â”€â”€â”€â–º Hohfeld classification\n",
        "××“×¨×©  â”€â”€â”€â”€â”€â”˜    Encoder        Space  â””â”€â”€â”€â”€â”€ (RIGHT/DUTY/LIBERTY/...)\n",
        "                                      \n",
        "Hebrew/Aramaic                        English\n",
        "500 BCE â€“ 1800 CE                     1956 â€“ 2020 CE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 4.1 âœ‚ï¸ Create Train/Test Splits { display-mode: \"form\" }\n",
        "#@markdown Splits data by **time period** (not randomly!):\n",
        "#@markdown - **Train:** Ancient Hebrew texts (500 BCE â€“ 1500 CE)\n",
        "#@markdown - **Valid:** Early modern Hebrew (1500 â€“ 1800 CE)\n",
        "#@markdown - **Test:** Modern English Dear Abby (1956 â€“ 2020 CE)\n",
        "\n",
        "show_progress(4)\n",
        "\n",
        "import json\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "print(\"Creating temporal splits...\")\n",
        "print()\n",
        "\n",
        "# Define time periods\n",
        "TRAIN_PERIODS = {'BIBLICAL', 'SECOND_TEMPLE', 'TANNAITIC', 'AMORAIC', 'GEONIC', 'RISHONIM'}\n",
        "VALID_PERIODS = {'ACHRONIM'}\n",
        "TEST_PERIODS = {'DEAR_ABBY'}\n",
        "\n",
        "# Collect passage IDs by period\n",
        "train_ids, valid_ids, test_ids = [], [], []\n",
        "\n",
        "with open(\"data/processed/passages.jsonl\", 'r') as f:\n",
        "    for line in f:\n",
        "        p = json.loads(line)\n",
        "        pid = p['id']\n",
        "        period = p['time_period']\n",
        "        \n",
        "        if period in TRAIN_PERIODS:\n",
        "            train_ids.append(pid)\n",
        "        elif period in VALID_PERIODS:\n",
        "            valid_ids.append(pid)\n",
        "        elif period in TEST_PERIODS:\n",
        "            test_ids.append(pid)\n",
        "\n",
        "# Shuffle\n",
        "random.shuffle(train_ids)\n",
        "random.shuffle(valid_ids)\n",
        "random.shuffle(test_ids)\n",
        "\n",
        "# Save splits\n",
        "splits = {\n",
        "    'ancient_to_modern': {\n",
        "        'name': 'Ancient Hebrew â†’ Modern English',\n",
        "        'train_ids': train_ids,\n",
        "        'valid_ids': valid_ids,\n",
        "        'test_ids': test_ids,\n",
        "        'train_size': len(train_ids),\n",
        "        'valid_size': len(valid_ids),\n",
        "        'test_size': len(test_ids),\n",
        "    }\n",
        "}\n",
        "\n",
        "os.makedirs(\"data/splits\", exist_ok=True)\n",
        "with open(\"data/splits/all_splits.json\", 'w') as f:\n",
        "    json.dump(splits, f, indent=2)\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# DISPLAY SPLITS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"â•\" * 50)\n",
        "print(\"âœ‚ï¸ TEMPORAL SPLIT\")\n",
        "print(\"â•\" * 50)\n",
        "print()\n",
        "print(\"                    TRAIN           VALID           TEST\")\n",
        "print(\"                    â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€           â”€â”€â”€â”€\")\n",
        "print(f\"  Era:              Ancient         Early Modern    Modern\")\n",
        "print(f\"  Dates:            500 BCE-1500    1500-1800       1956-2020\")\n",
        "print(f\"  Language:         Hebrew/Aramaic  Hebrew          English\")\n",
        "print(f\"  Passages:         {len(train_ids):>10,}      {len(valid_ids):>10,}      {len(test_ids):>10,}\")\n",
        "print()\n",
        "print(\"The model will NEVER see English during training.\")\n",
        "print(\"Transfer to Dear Abby is a true zero-shot test.\")\n",
        "\n",
        "# Backup\n",
        "os.makedirs(f\"{SAVE_DIR}/splits\", exist_ok=True)\n",
        "import shutil\n",
        "shutil.copy(\"data/splits/all_splits.json\", f\"{SAVE_DIR}/splits/\")\n",
        "\n",
        "show_progress(4, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 4.2 ğŸ§  Define Model Architecture { display-mode: \"form\" }\n",
        "#@markdown The **Bond Invariance Principle (BIP)** architecture:\n",
        "#@markdown \n",
        "#@markdown 1. **Multilingual Encoder** - Maps Hebrew and English to shared space\n",
        "#@markdown 2. **Bond Projection** - Extracts moral structure (z_bond)\n",
        "#@markdown 3. **Adversarial Head** - Ensures z_bond doesn't encode time period\n",
        "#@markdown 4. **Hohfeld Classifier** - Predicts moral relation from z_bond\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "print(\"â•\" * 50)\n",
        "print(\"ğŸ§  BIP MODEL ARCHITECTURE\")\n",
        "print(\"â•\" * 50)\n",
        "print()\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# GRADIENT REVERSAL LAYER\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class GradientReversal(torch.autograd.Function):\n",
        "    \"\"\"Reverses gradients during backprop - key to adversarial disentanglement.\"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.clone()\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return -ctx.lambda_ * grad_output, None\n",
        "\n",
        "def gradient_reversal(x, lambda_=1.0):\n",
        "    return GradientReversal.apply(x, lambda_)\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# BIP MODEL\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class BIPModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Bond Invariance Principle Model\n",
        "    \n",
        "    Learns a 'bond space' representation that:\n",
        "    - CAN predict Hohfeldian moral relations\n",
        "    - CANNOT predict time period (via adversarial training)\n",
        "    \n",
        "    If transfer works, moral structure is time-invariant.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, d_model=384, d_bond=64, n_periods=14, n_hohfeld=4):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Multilingual encoder (Hebrew + English in same space)\n",
        "        self.encoder = AutoModel.from_pretrained(\n",
        "            \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "        )\n",
        "        \n",
        "        # Project to bond space\n",
        "        self.bond_proj = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(d_model // 2, d_bond)\n",
        "        )\n",
        "        \n",
        "        # Hohfeld classifier (from bond space)\n",
        "        self.hohfeld_classifier = nn.Linear(d_bond, n_hohfeld)\n",
        "        \n",
        "        # Time classifier (adversarial - should FAIL)\n",
        "        self.time_classifier = nn.Linear(d_bond, n_periods)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, adversarial_lambda=1.0):\n",
        "        # Encode text\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        h = outputs.last_hidden_state\n",
        "        \n",
        "        # Mean pooling\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (h * mask).sum(1) / mask.sum(1).clamp(min=1e-9)\n",
        "        \n",
        "        # Project to bond space\n",
        "        z_bond = self.bond_proj(pooled)\n",
        "        \n",
        "        # Predictions\n",
        "        hohfeld_pred = self.hohfeld_classifier(z_bond)\n",
        "        \n",
        "        # Adversarial time prediction (gradient reversed)\n",
        "        z_bond_adv = gradient_reversal(z_bond, adversarial_lambda)\n",
        "        time_pred = self.time_classifier(z_bond_adv)\n",
        "        \n",
        "        return {\n",
        "            'z_bond': z_bond,\n",
        "            'hohfeld_pred': hohfeld_pred,\n",
        "            'time_pred': time_pred,\n",
        "        }\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# SHOW ARCHITECTURE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
        "print(\"â”‚                     BIP Architecture                        â”‚\")\n",
        "print(\"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
        "print(\"â”‚                                                             â”‚\")\n",
        "print(\"â”‚   Input (Hebrew/English) â”€â”€â–º Multilingual Encoder (384d)   â”‚\")\n",
        "print(\"â”‚                                      â”‚                      â”‚\")\n",
        "print(\"â”‚                                      â–¼                      â”‚\")\n",
        "print(\"â”‚                              Bond Projection                â”‚\")\n",
        "print(\"â”‚                                      â”‚                      â”‚\")\n",
        "print(\"â”‚                                      â–¼                      â”‚\")\n",
        "print(\"â”‚                               z_bond (64d)                  â”‚\")\n",
        "print(\"â”‚                              â•±           â•²                  â”‚\")\n",
        "print(\"â”‚                             â•±             â•²                 â”‚\")\n",
        "print(\"â”‚                            â–¼               â–¼                â”‚\")\n",
        "print(\"â”‚                    Hohfeld Head      [GRL] Time Head        â”‚\")\n",
        "print(\"â”‚                    (SHOULD WORK)     (SHOULD FAIL)          â”‚\")\n",
        "print(\"â”‚                                                             â”‚\")\n",
        "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
        "print()\n",
        "print(\"GRL = Gradient Reversal Layer\")\n",
        "print(\"      Makes z_bond UNINFORMATIVE about time period\")\n",
        "print(\"      While remaining INFORMATIVE about moral structure\")\n",
        "print()\n",
        "\n",
        "# Create model and count parameters\n",
        "model = BIPModel().to(device)\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"âœ“ Model created: {n_params:,} parameters\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 4.3 ğŸš€ Train the Model { display-mode: \"form\" }\n",
        "#@markdown This is the main training loop. Expected time:\n",
        "#@markdown - **L4 GPU (optimized):** ~30-45 min per epoch\n",
        "#@markdown - **T4 GPU:** ~2+ hours per epoch\n",
        "#@markdown \n",
        "#@markdown Watch for:\n",
        "#@markdown - **Hohfeld accuracy** should increase (learning moral structure)\n",
        "#@markdown - **Time accuracy** should stay low (adversarial working)\n",
        "\n",
        "show_progress(5)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# DATASET\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "TIME_PERIOD_TO_IDX = {\n",
        "    'BIBLICAL': 0, 'SECOND_TEMPLE': 1, 'TANNAITIC': 2, 'AMORAIC': 3,\n",
        "    'GEONIC': 4, 'RISHONIM': 5, 'ACHRONIM': 6, 'MODERN_HEBREW': 7,\n",
        "    'CONFUCIAN': 8, 'DAOIST': 9, 'MOHIST': 10,\n",
        "    'QURANIC': 11, 'HADITH': 12,\n",
        "    'DEAR_ABBY': 13,\n",
        "}\n",
        "\n",
        "HOHFELD_TO_IDX = {'OBLIGATION': 0, 'RIGHT': 1, 'LIBERTY': 2, 'NO_RIGHT': 3, None: 3}\n",
        "\n",
        "class MoralDataset(Dataset):\n",
        "    def __init__(self, passage_ids, passages_file, bonds_file, tokenizer, max_len=128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.data = []\n",
        "        \n",
        "        passage_ids = set(passage_ids)\n",
        "        \n",
        "        with open(passages_file, 'r') as f_pass, open(bonds_file, 'r') as f_bond:\n",
        "            for p_line, b_line in zip(f_pass, f_bond):\n",
        "                p = json.loads(p_line)\n",
        "                if p['id'] in passage_ids:\n",
        "                    b = json.loads(b_line)\n",
        "                    # Use ORIGINAL language (Hebrew for ancient, English for modern)\n",
        "                    text = p.get('text_original', '') if p.get('language') != 'english' else p.get('text_english', '')\n",
        "                    self.data.append({\n",
        "                        'text': text[:1000],\n",
        "                        'time_period': p['time_period'],\n",
        "                        'hohfeld': b['bond_structure'].get('hohfeld_state')\n",
        "                    })\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            item['text'],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'time_label': TIME_PERIOD_TO_IDX.get(item['time_period'], 13),\n",
        "            'hohfeld_label': HOHFELD_TO_IDX.get(item['hohfeld'], 3)\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'input_ids': torch.stack([x['input_ids'] for x in batch]),\n",
        "        'attention_mask': torch.stack([x['attention_mask'] for x in batch]),\n",
        "        'time_labels': torch.tensor([x['time_label'] for x in batch]),\n",
        "        'hohfeld_labels': torch.tensor([x['hohfeld_label'] for x in batch])\n",
        "    }\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# LOAD DATA\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "print(\"Loading splits...\")\n",
        "with open(\"data/splits/all_splits.json\", 'r') as f:\n",
        "    splits = json.load(f)\n",
        "\n",
        "split = splits['ancient_to_modern']\n",
        "\n",
        "print(\"Creating datasets...\")\n",
        "train_dataset = MoralDataset(split['train_ids'], \"data/processed/passages.jsonl\", \n",
        "                             \"data/processed/bond_structures.jsonl\", tokenizer)\n",
        "valid_dataset = MoralDataset(split['valid_ids'], \"data/processed/passages.jsonl\",\n",
        "                             \"data/processed/bond_structures.jsonl\", tokenizer)\n",
        "test_dataset = MoralDataset(split['test_ids'], \"data/processed/passages.jsonl\",\n",
        "                            \"data/processed/bond_structures.jsonl\", tokenizer)\n",
        "\n",
        "print(f\"  Train: {len(train_dataset):,} passages (Hebrew)\")\n",
        "print(f\"  Valid: {len(valid_dataset):,} passages (Hebrew)\")\n",
        "print(f\"  Test:  {len(test_dataset):,} passages (English)\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE*2, shuffle=False,\n",
        "                          collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE*2, shuffle=False,\n",
        "                         collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# TRAINING LOOP\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
        "\n",
        "print()\n",
        "print(\"â•\" * 50)\n",
        "print(\"ğŸš€ TRAINING\")\n",
        "print(\"â•\" * 50)\n",
        "print()\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "training_history = []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    epoch_start = time.time()\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", unit=\"batch\")\n",
        "    \n",
        "    for batch in pbar:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        time_labels = batch['time_labels'].to(device)\n",
        "        hohfeld_labels = batch['hohfeld_labels'].to(device)\n",
        "        \n",
        "        if USE_AMP:\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                outputs = model(input_ids, attention_mask, adversarial_lambda=1.0)\n",
        "                loss_hohfeld = F.cross_entropy(outputs['hohfeld_pred'], hohfeld_labels)\n",
        "                loss_time = F.cross_entropy(outputs['time_pred'], time_labels)\n",
        "                loss = loss_hohfeld + loss_time\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(input_ids, attention_mask, adversarial_lambda=1.0)\n",
        "            loss_hohfeld = F.cross_entropy(outputs['hohfeld_pred'], hohfeld_labels)\n",
        "            loss_time = F.cross_entropy(outputs['time_pred'], time_labels)\n",
        "            loss = loss_hohfeld + loss_time\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    hohfeld_correct = 0\n",
        "    time_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in valid_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            time_labels = batch['time_labels'].to(device)\n",
        "            hohfeld_labels = batch['hohfeld_labels'].to(device)\n",
        "            \n",
        "            outputs = model(input_ids, attention_mask, adversarial_lambda=0)\n",
        "            valid_loss += F.cross_entropy(outputs['hohfeld_pred'], hohfeld_labels).item()\n",
        "            \n",
        "            hohfeld_correct += (outputs['hohfeld_pred'].argmax(-1) == hohfeld_labels).sum().item()\n",
        "            time_correct += (outputs['time_pred'].argmax(-1) == time_labels).sum().item()\n",
        "            total += len(hohfeld_labels)\n",
        "    \n",
        "    epoch_time = time.time() - epoch_start\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    avg_valid_loss = valid_loss / len(valid_loader)\n",
        "    hohfeld_acc = 100 * hohfeld_correct / total\n",
        "    time_acc = 100 * time_correct / total\n",
        "    \n",
        "    training_history.append({\n",
        "        'epoch': epoch,\n",
        "        'train_loss': avg_train_loss,\n",
        "        'valid_loss': avg_valid_loss,\n",
        "        'hohfeld_acc': hohfeld_acc,\n",
        "        'time_acc': time_acc,\n",
        "    })\n",
        "    \n",
        "    print()\n",
        "    print(f\"  Epoch {epoch} complete in {epoch_time/60:.1f} min\")\n",
        "    print(f\"  â”œâ”€ Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  â”œâ”€ Valid Loss: {avg_valid_loss:.4f}\")\n",
        "    print(f\"  â”œâ”€ Hohfeld Acc: {hohfeld_acc:.1f}% (want: HIGH)\")\n",
        "    print(f\"  â””â”€ Time Acc: {time_acc:.1f}% (want: LOW ~{100/14:.0f}%)\")\n",
        "    \n",
        "    # Save best model\n",
        "    if avg_valid_loss < best_valid_loss:\n",
        "        best_valid_loss = avg_valid_loss\n",
        "        torch.save(model.state_dict(), \"models/checkpoints/best_model.pt\")\n",
        "        import shutil\n",
        "        shutil.copy(\"models/checkpoints/best_model.pt\", f\"{SAVE_DIR}/best_model.pt\")\n",
        "        print(f\"  âœ“ Saved best model (backed up to Drive)\")\n",
        "\n",
        "print()\n",
        "print(\"â•\" * 50)\n",
        "print(\"âœ“ TRAINING COMPLETE\")\n",
        "print(\"â•\" * 50)\n",
        "\n",
        "show_progress(5, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 5: The Moment of Truth\n",
        "---\n",
        "\n",
        "The model was trained on **Hebrew texts from 500 BCE â€“ 1800 CE**.\n",
        "\n",
        "Now we test it on **English texts from 1956 â€“ 2020**.\n",
        "\n",
        "### What We're Looking For\n",
        "\n",
        "| Metric | Good Result | Bad Result |\n",
        "|--------|-------------|------------|\n",
        "| **Hohfeld Accuracy** | >30% (chance=25%) | ~25% |\n",
        "| **Statistical Significance** | p < 0.001 | p > 0.05 |\n",
        "| **Effect Size (Cohen's h)** | >0.2 | <0.1 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 5.1 ğŸ“Š Evaluate Cross-Lingual Transfer { display-mode: \"form\" }\n",
        "#@markdown Tests the Hebrew-trained model on English Dear Abby letters.\n",
        "#@markdown \n",
        "#@markdown **This is the main result of the experiment.**\n",
        "\n",
        "show_progress(6)\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "print(\"â•\" * 50)\n",
        "print(\"ğŸ“Š CROSS-LINGUAL TRANSFER EVALUATION\")\n",
        "print(\"â•\" * 50)\n",
        "print()\n",
        "print(\"Testing Hebrew-trained model on English...\")\n",
        "print()\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(\"models/checkpoints/best_model.pt\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Collect predictions\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_time_preds = []\n",
        "all_time_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing on English\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        \n",
        "        outputs = model(input_ids, attention_mask, adversarial_lambda=0)\n",
        "        \n",
        "        all_preds.extend(outputs['hohfeld_pred'].argmax(-1).cpu().tolist())\n",
        "        all_labels.extend(batch['hohfeld_labels'].tolist())\n",
        "        all_time_preds.extend(outputs['time_pred'].argmax(-1).cpu().tolist())\n",
        "        all_time_labels.extend(batch['time_labels'].tolist())\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# COMPUTE METRICS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "hohfeld_acc = 100 * sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_preds)\n",
        "time_acc = 100 * sum(p == l for p, l in zip(all_time_preds, all_time_labels)) / len(all_time_preds)\n",
        "\n",
        "# Statistical test vs chance (25%)\n",
        "n = len(all_preds)\n",
        "p_observed = hohfeld_acc / 100\n",
        "p_chance = 0.25\n",
        "se = np.sqrt(p_chance * (1 - p_chance) / n)\n",
        "z_score = (p_observed - p_chance) / se\n",
        "p_value = 1 - stats.norm.cdf(z_score)  # One-tailed\n",
        "\n",
        "# Effect size (Cohen's h)\n",
        "h1 = 2 * np.arcsin(np.sqrt(p_observed))\n",
        "h0 = 2 * np.arcsin(np.sqrt(p_chance))\n",
        "cohens_h = h1 - h0\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# DISPLAY RESULTS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print()\n",
        "print(\"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
        "print(\"â”‚                     MAIN RESULTS                          â”‚\")\n",
        "print(\"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
        "print(f\"â”‚                                                           â”‚\")\n",
        "print(f\"â”‚   Hohfeld Accuracy:    {hohfeld_acc:5.1f}%  (chance = 25.0%)       â”‚\")\n",
        "print(f\"â”‚   Time Accuracy:       {time_acc:5.1f}%  (chance = ~7%)          â”‚\")\n",
        "print(f\"â”‚                                                           â”‚\")\n",
        "print(f\"â”‚   z-score:             {z_score:5.1f}                             â”‚\")\n",
        "print(f\"â”‚   p-value:             {p_value:.2e}                        â”‚\")\n",
        "print(f\"â”‚   Cohen's h:           {cohens_h:5.3f}                            â”‚\")\n",
        "print(f\"â”‚                                                           â”‚\")\n",
        "print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
        "print()\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.001 and cohens_h > 0.2:\n",
        "    print(\"ğŸ‰ RESULT: STRONG EVIDENCE FOR UNIVERSAL MORAL STRUCTURE\")\n",
        "    print()\n",
        "    print(\"   The model learned moral relations in ancient Hebrew\")\n",
        "    print(\"   and successfully transferred to modern English.\")\n",
        "    print()\n",
        "    print(\"   Hohfeldian structure appears to be invariant across\")\n",
        "    print(\"   2,500 years and the Semitic-Germanic language boundary.\")\n",
        "elif p_value < 0.05:\n",
        "    print(\"ğŸ“ˆ RESULT: WEAK EVIDENCE FOR TRANSFER\")\n",
        "    print()\n",
        "    print(\"   Transfer is statistically significant but effect size is small.\")\n",
        "    print(\"   More data or refined methods may strengthen the result.\")\n",
        "else:\n",
        "    print(\"âŒ RESULT: NO EVIDENCE FOR TRANSFER\")\n",
        "    print()\n",
        "    print(\"   The model did not transfer from Hebrew to English.\")\n",
        "    print(\"   This could mean:\")\n",
        "    print(\"   - Moral structure is NOT universal\")\n",
        "    print(\"   - Our operationalization is inadequate\")\n",
        "    print(\"   - More training data is needed\")\n",
        "\n",
        "show_progress(6, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title 5.2 ğŸ”¬ Statistical Analysis & Visualization { display-mode: \"form\" }\n",
        "#@markdown Creates publication-ready figures and detailed statistics.\n",
        "\n",
        "show_progress(7)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# PLOT 1: Training History\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "ax1 = axes[0]\n",
        "epochs = [h['epoch'] for h in training_history]\n",
        "ax1.plot(epochs, [h['train_loss'] for h in training_history], 'b-o', label='Train Loss')\n",
        "ax1.plot(epochs, [h['valid_loss'] for h in training_history], 'r-o', label='Valid Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training Progress')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# PLOT 2: Accuracy Comparison\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "ax2 = axes[1]\n",
        "categories = ['Hohfeld\\n(Moral Structure)', 'Time Period\\n(Should Fail)']\n",
        "accuracies = [hohfeld_acc, time_acc]\n",
        "chance_levels = [25, 100/14]\n",
        "\n",
        "x = np.arange(len(categories))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax2.bar(x - width/2, accuracies, width, label='Model', color=['green', 'red'])\n",
        "bars2 = ax2.bar(x + width/2, chance_levels, width, label='Chance', color='gray', alpha=0.5)\n",
        "\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Transfer Results')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(categories)\n",
        "ax2.legend()\n",
        "ax2.set_ylim(0, 100)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars1, accuracies):\n",
        "    ax2.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
        "                 xytext=(0, 3), textcoords='offset points', ha='center')\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# PLOT 3: Confusion Matrix\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "ax3 = axes[2]\n",
        "cm = confusion_matrix(all_labels, all_preds, normalize='true')\n",
        "labels = ['OBLIGATION', 'RIGHT', 'LIBERTY', 'NONE']\n",
        "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', ax=ax3,\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "ax3.set_xlabel('Predicted')\n",
        "ax3.set_ylabel('True')\n",
        "ax3.set_title('Hohfeld Confusion Matrix')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results/bip_results.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Save to Drive\n",
        "import shutil\n",
        "os.makedirs(f\"{SAVE_DIR}/figures\", exist_ok=True)\n",
        "shutil.copy(\"results/bip_results.png\", f\"{SAVE_DIR}/figures/\")\n",
        "\n",
        "print()\n",
        "print(\"âœ“ Figures saved to Google Drive\")\n",
        "\n",
        "show_progress(7, \"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Conclusion\n",
        "---\n",
        "\n",
        "## What We Tested\n",
        "\n",
        "Whether a neural network trained on ancient Hebrew moral reasoning can classify moral relations in modern English.\n",
        "\n",
        "## What This Means\n",
        "\n",
        "<details>\n",
        "<summary><b>If Transfer Succeeded (p < 0.001)</b></summary>\n",
        "\n",
        "There exists an invariant structure to moral cognition that:\n",
        "- Transcends the Hebrew-English language barrier\n",
        "- Persists across 2,500 years\n",
        "- Spans religious-legal and secular-personal contexts\n",
        "\n",
        "This is evidence for **relational moral objectivity**:\n",
        "> Morality is neither divine command nor social construction, but the invariant structure of relations between agents.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary><b>If Transfer Failed (p > 0.05)</b></summary>\n",
        "\n",
        "Either:\n",
        "1. Moral structure is NOT universal (cultures differ fundamentally)\n",
        "2. Hohfeldian relations are not the right operationalization\n",
        "3. The model/data are inadequate for this test\n",
        "\n",
        "This would be interesting too â€” a principled negative result.\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "## Citation\n",
        "\n",
        "```bibtex\n",
        "@article{bond2025bip,\n",
        "  title={The Relational Structure of Moral Cognition: \n",
        "         Evidence for Universal Invariance Across Language, Culture, and Time},\n",
        "  author={Bond, Andrew Harper},\n",
        "  journal={[TBD]},\n",
        "  year={2025}\n",
        "}\n",
        "```\n",
        "\n",
        "## Code & Data\n",
        "\n",
        "ğŸ“‚ **Repository:** [github.com/ahb-sjsu/sqnd-probe](https://github.com/ahb-sjsu/sqnd-probe)\n",
        "\n",
        "---\n",
        "\n",
        "*\"The rabbis of the Talmud and the readers of Dear Abby, separated by 2,000 years and speaking different languages, were navigating the same moral geometry. We have now measured that geometry.\"*"
      ]
    }
  ]
}
